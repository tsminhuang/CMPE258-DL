{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsungmin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Function define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x, n_class):\n",
    "    \"\"\"\n",
    "    One Hot encoding\n",
    "    \n",
    "    Inputs:\n",
    "    - x: N smaple vector\n",
    "    - n_class: Number of class\n",
    "    \n",
    "    Returns:\n",
    "    - en_1hot: Encoding matrix shape of (n_smaple, n_class)\n",
    "    \"\"\"\n",
    "    \n",
    "    en_1hot = np.zeros([len(x), n_class])\n",
    "    \n",
    "    for idx, cat in enumerate(x):\n",
    "        en_1hot[idx, cat] = 1\n",
    "\n",
    "    return en_1hot\n",
    "\n",
    "def next_batch(X, y, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Get next batch data\n",
    "    \n",
    "    Inputs: \n",
    "    - X: input data\n",
    "    - y: input data label\n",
    "    - batch_size: s\n",
    "    \n",
    "    Outputs tuple of batch data \n",
    "    - X_batch: batch sampled X \n",
    "    - y_batch: batch sampled y\n",
    "    \"\"\"\n",
    "    \n",
    "    n_sample = X.shape[0]\n",
    "    n_batch = n_sample // batch_size\n",
    "    n_batch = n_batch + 1 if (n_sample % n_batch) != 0 else n_batch \n",
    "    idx = np.array(range(n_sample))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "    for b_idx in range(n_batch):\n",
    "        start, end = b_idx * batch_size, (b_idx + 1) * batch_size\n",
    "        if end >= n_sample:\n",
    "            sample_idx = idx[start:]\n",
    "        else:\n",
    "            sample_idx = idx[start:end] \n",
    "        \n",
    "        X_batch, y_batch = X[sample_idx, :], y[sample_idx, :]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "\n",
    "def xavier_initializer(n_inputs, n_outputs, shape):\n",
    "    \"\"\"\n",
    "    xavier initizlize \n",
    "    \n",
    "    Inputs:\n",
    "    - n_inputs: Number of input neurons\n",
    "    - n_outpus: Number of output neurons\n",
    "    - shape: shape of output\n",
    "    \n",
    "    Returns:\n",
    "    - output: array of shape \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    init_range = np.sqrt(6.0 / ((n_inputs + n_outputs)))\n",
    "    \n",
    "    return  tf.random_uniform(shape, -init_range, init_range)\n",
    "\n",
    "\n",
    "def get_output_size(input_size, ksize, n_filters, stride, pad):\n",
    "    \"\"\"\n",
    "    Get output size of layer\n",
    "    \n",
    "    Inputs:\n",
    "    - input_size: shape of input data\n",
    "    - ksize: kernel size\n",
    "    - n_filters: number of output channel\n",
    "    - stride: Stride steps\n",
    "    - pad: Pad steps\n",
    "    \n",
    "    Returns:\n",
    "    - output_size: output size\n",
    "    \"\"\"\n",
    "\n",
    "    NH, NW, ND = input_size\n",
    "    KH, KW = ksize\n",
    "    OH = (NH + 2 * pad - KH) // stride + 1\n",
    "    OW = (NW + 2 * pad - KW) // stride + 1\n",
    "\n",
    "    output_size = (OH, OW, n_filters)\n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_norm(X, mu=None, sigma=None):\n",
    "    \"\"\"\n",
    "    Standard normalize input data X with mu and sigma.\n",
    "    If mu and sigma not given compute from input data X\n",
    "    \n",
    "    Inputs:\n",
    "    - X: Input data of shape (N, H, W, C)\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - X_sc: Standard normalize of X \n",
    "    - mu: Mean of x of shape\n",
    "    - sigma: standard deviation of x of shape\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if mu is None:\n",
    "        mu = np.mean(X, axis=0, keepdims=True)\n",
    "    X_sc = X - mu\n",
    "    \n",
    "    if sigma is None:\n",
    "        sigma = np.std(X, axis=0, keepdims=True)\n",
    "    X_sc = X_sc / sigma\n",
    "    \n",
    "    return X_sc, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('exam2_train_x.npy')\n",
    "y_train = np.load('exam2_train_y.npy')\n",
    "y_train_en = one_hot_encode(y_train, 6)\n",
    "X_train_sc, mu, sigma = std_norm(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('exam2_test_x.npy')\n",
    "y_test = np.load('exam2_test_y.npy')\n",
    "y_test_en = one_hot_encode(y_test, 6)\n",
    "X_test_sc, mu, sigama = std_norm(X_test, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Initialize parameters (Weights, bias for each layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer, input_size, layer_type):\n",
    "    \"\"\"\n",
    "    Initialize layer weights and its output size\n",
    "    \n",
    "    Inputs:\n",
    "    - layer: Layer data structure in dictionary\n",
    "    - input_size: Input size of layer\n",
    "    - layer type: Layer type\n",
    "    \n",
    "    Returns:\n",
    "    - output_size: Layer output shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    output_size = None\n",
    "    # only conv and fc layer need weights initialize\n",
    "    if layer_type == 'conv':  \n",
    "        \n",
    "        NH, NW, ND = input_size\n",
    "        params = layer['conv_params']\n",
    "        stride = params['stride']\n",
    "        padding = params['padding']\n",
    "        KH, KW = params['ksize']\n",
    "        KF = params['n_filters']\n",
    "        \n",
    "        # FIXME: pad should depend on ksize (KH, KW)\n",
    "        if padding == 'SAME':\n",
    "            pad = KH // 2\n",
    "        else:\n",
    "            pad = 0\n",
    "        \n",
    "        output_size = \\\n",
    "            get_output_size(input_size, (KH, KW), KF, stride, pad)\n",
    "        \n",
    "        # weights initialize\n",
    "        n_inputs = KH * KW * ND\n",
    "        n_outputs = KH * KW * KF\n",
    "         \n",
    "        w_shape = (KH, KW, ND, KF)\n",
    "        w = tf.Variable(xavier_initializer(n_inputs, n_outputs, w_shape))\n",
    "        b = tf.Variable(tf.zeros(KF))\n",
    "        layer['w'], layer['b'] = w, b\n",
    "        \n",
    "        \n",
    "    elif layer_type == 'pool':\n",
    "        \n",
    "        NH, NW, ND = input_size\n",
    "        params = layer['pool_params']\n",
    "        stride = params['stride']\n",
    "        KH, KW = params['ksize']\n",
    "        padding = params['padding']\n",
    "        \n",
    "        # FIXME: pad should depend on ksize (KH, KW)\n",
    "        if padding == 'SAME':\n",
    "            pad = KH // 2\n",
    "        else:\n",
    "            pad = 0\n",
    "        \n",
    "        output_size = \\\n",
    "            get_output_size(input_size, (KH, KW), ND, stride, pad)\n",
    "                \n",
    "    elif layer_type == 'fc':\n",
    "        \n",
    "        params = layer['params']\n",
    "        n_inputs = np.prod(input_size)\n",
    "        n_outputs = params['n_outputs']\n",
    "        \n",
    "        output_size = n_outputs\n",
    "        \n",
    "        # weights initialize\n",
    "        w_shape = (n_inputs, n_outputs)\n",
    "        w = tf.Variable(xavier_initializer(n_inputs, n_outputs, w_shape))\n",
    "        b = tf.Variable(tf.zeros(n_outputs))\n",
    "        layer['w'], layer['b'] = w, b\n",
    "\n",
    "    # other layer\n",
    "    else:\n",
    "        output_size = input_size\n",
    "            \n",
    "    return output_size\n",
    "            \n",
    "def model_init(model, input_size):\n",
    "    \"\"\"\n",
    "    Initialize the cnn model\n",
    "    \n",
    "    Inputs:\n",
    "    - input_size: Input data size\n",
    "    \n",
    "    \"\"\"\n",
    "    for layer in model:\n",
    "        layer_type = layer['name']\n",
    "        for sub_layer in layer_type.split('_'):\n",
    "            input_size = layer_init(layer, input_size, sub_layer)\n",
    "        layer['output_size'] = input_size\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "{\n",
    "    # Using '_' to define sandwish layer\n",
    "    'name': 'conv_relu_pool',\n",
    "    'conv_params': \n",
    "        { 'ksize': (3, 3), 'stride': 1, 'padding': 'SAME', 'n_filters': 8,\n",
    "          'l2_reg': 1e-3 },\n",
    "    'pool_params':\n",
    "        { 'ksize': (2, 2), 'stride': 2, 'padding': 'VALID' },\n",
    "},\n",
    "{   \n",
    "    'name': 'conv_relu_pool',\n",
    "    'conv_params': \n",
    "        { 'ksize': (3, 3), 'stride': 1, 'padding': 'SAME', 'n_filters': 16,\n",
    "          'l2_reg': 1e-3 },\n",
    "    'pool_params': \n",
    "        { 'ksize': (2, 2), 'stride': 2, 'padding': 'VALID' },\n",
    "},\n",
    "# {\n",
    "#     'name': 'dropout',\n",
    "#     'params' : { 'keep_prob': 0.2 }\n",
    "# },\n",
    "{   \n",
    "    'name': 'conv_relu_pool',\n",
    "    'conv_params': \n",
    "        { 'ksize': (3, 3), 'stride': 1, 'padding': 'SAME', 'n_filters': 32,\n",
    "          'l2_reg': 1e-3 },\n",
    "    'pool_params': \n",
    "        { 'ksize': (2, 2), 'stride': 2, 'padding': 'VALID' },\n",
    "},\n",
    "{   \n",
    "    'name': 'conv_relu_pool',\n",
    "    'conv_params': \n",
    "        { 'ksize': (3, 3), 'stride': 1, 'padding': 'SAME', 'n_filters': 64,\n",
    "          'l2_reg': 1e-3 },\n",
    "    'pool_params': \n",
    "        { 'ksize': (2, 2), 'stride': 2, 'padding': 'VALID' },\n",
    "},\n",
    "{\n",
    "    'name': 'dropout',\n",
    "    'params' : { 'keep_prob': 0.2 }\n",
    "},\n",
    "# {   \n",
    "#     'name': 'conv_relu_pool',\n",
    "#     'conv_params': \n",
    "#         { 'ksize': (3, 3), 'stride': 1, 'padding': 'SAME', 'n_filters': 128,\n",
    "#           'l2_reg': 1e-2 },\n",
    "#     'pool_params': \n",
    "#         { 'ksize': (2, 2), 'stride': 2, 'padding': 'VALID' },\n",
    "# },\n",
    "{\n",
    "    'name': 'fc_relu',\n",
    "    'params':  { 'n_outputs': 128, 'l2_reg': 1e-3 },\n",
    "},\n",
    "{    \n",
    "    'name': 'fc', #'fc_sigmoid',\n",
    "    'params': { 'n_outputs': 6, 'l2_reg': 1e-3 },\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (64, 64, 3)\n",
    "model = model_init(model, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Optimization of Convolution Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model, input_size):\n",
    "    \"\"\"\n",
    "    Show the model layer infomation\n",
    "    \n",
    "    Inputs: \n",
    "    - model: CNN mode \n",
    "    - input_size: input size of model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    msg_format = \\\n",
    "        '{type:10s} | {sz:12s} | {ksize:12s} | {stride:6s} | {padding:7s} | {l2_reg:6s}'\n",
    "            \n",
    "    msg_header = {\n",
    "            'type': 'Type', 'sz': 'Output Size', 'ksize': 'Kernel Size',\n",
    "            'stride': 'Stride', 'padding': 'Padding', 'l2_reg': 'L2 reg'\n",
    "    }\n",
    "    \n",
    "    def layer_summary(input_size, layer, layer_type):\n",
    "        \"\"\"\n",
    "        Show layer information\n",
    "        \n",
    "        Inputs:\n",
    "        - input_size: niput size of layer\n",
    "        - layer: layer config \n",
    "        - layer_type: layer type\n",
    "        \"\"\"\n",
    "        \n",
    "        layer_info = {\n",
    "            'type': '', \n",
    "            'sz': '', 'chs': '', 'ksize': '',\n",
    "            'stride': '', 'padding': '',\n",
    "            'l2_reg': '',\n",
    "        }\n",
    "        \n",
    "        output_size = None\n",
    "        \n",
    "        if layer_type == 'conv':\n",
    "            \n",
    "            NH, NW, ND = input_size\n",
    "            params = layer['conv_params']\n",
    "            stride = params['stride']\n",
    "            padding = params['padding']\n",
    "            KH, KW = params['ksize']\n",
    "            KF = params['n_filters']\n",
    "            \n",
    "            # FIXME: pad should depend on ksize (KH, KW)\n",
    "            if padding == 'SAME':\n",
    "                pad = KH // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "            \n",
    "            channel = KF\n",
    "            \n",
    "            output_size = \\\n",
    "                get_output_size(input_size, [KH, KW], KF, stride, pad)\n",
    "            \n",
    "            layer_info['sz'] = str(output_size)\n",
    "            layer_info['ksize'] = str(params['ksize'])\n",
    "            layer_info['stride'] = str(stride)\n",
    "            layer_info['padding'] = padding\n",
    "            \n",
    "            if 'l2_reg' in params:\n",
    "                layer_info['l2_reg'] = str('{:.1e}'.format(params['l2_reg']))\n",
    "            \n",
    "        elif layer_type == 'pool':\n",
    "            \n",
    "            NH, NW, ND = input_size\n",
    "            params = layer['pool_params']\n",
    "            stride = params['stride']\n",
    "            padding = params['padding']\n",
    "            KH, KW = params['ksize']\n",
    "            channel = ND\n",
    "            \n",
    "            # FIXME: pad should depend on ksize (KH, KW)\n",
    "            if padding == 'SAME':\n",
    "                pad = KH // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "            \n",
    "            output_size = \\\n",
    "                get_output_size(input_size, [KH, KW], ND, stride, pad)\n",
    "            \n",
    "            layer_info['sz'] = str(output_size)\n",
    "            layer_info['ksize'] = str((KH, KW))\n",
    "            layer_info['stride'] = str(stride)\n",
    "            layer_info['padding'] = padding\n",
    "            \n",
    "        elif layer_type == 'fc':\n",
    "            \n",
    "            params = layer['params']\n",
    "            output_size = params['n_outputs']\n",
    "            \n",
    "            layer_info['sz'] = str(output_size)\n",
    "            \n",
    "            if 'l2_reg' in params:\n",
    "                layer_info['l2_reg'] = str('{:.1e}'.format(params['l2_reg']))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            output_size = input_size\n",
    "            layer_info['sz'] = str(output_size)\n",
    "        \n",
    "        layer_info['type'] = layer_type\n",
    "        print(msg_format.format(**layer_info))\n",
    "        \n",
    "        return output_size\n",
    "    \n",
    "    print(msg_format.format(**msg_header))\n",
    "    print('-'*len(msg_format))\n",
    "    for layer in model:\n",
    "        layer_type = layer['name']\n",
    "        sub_layers = layer_type.split('_')\n",
    "        \n",
    "        for sub_layer in sub_layers:\n",
    "            output_size = layer_summary(input_size, layer, sub_layer)\n",
    "            input_size = output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_layer(input_, layer, layer_type, training):\n",
    "    \"\"\"\n",
    "    Build layer operations\n",
    "    \n",
    "    Inputs:\n",
    "    - input_: input tensor for layer\n",
    "    - layer: layer config\n",
    "    - layer_type: layer type\n",
    "    \n",
    "    Return:\n",
    "    - output: output tensor for layer\n",
    "    \"\"\"\n",
    "    \n",
    "    output = None\n",
    "    if layer_type == 'conv':\n",
    "        \n",
    "        params = layer['conv_params']\n",
    "        w = layer['w']\n",
    "        b = layer['b']\n",
    "        KH, KW = params['ksize']\n",
    "        stride = params['stride']\n",
    "        padding = params['padding']\n",
    "        \n",
    "        conv = tf.nn.conv2d(input_, w, \n",
    "                            strides=(1, stride, stride, 1), padding=padding)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        \n",
    "        \n",
    "    elif layer_type == 'pool':\n",
    "        \n",
    "        params = layer['pool_params']\n",
    "        \n",
    "        KH, KW = params['ksize']\n",
    "        stride = params['stride']\n",
    "        padding = params['padding']\n",
    "        \n",
    "        output = tf.nn.max_pool(input_,\n",
    "                                ksize=(1, KH, KW , 1),\n",
    "                                strides=(1, stride, stride, 1), padding=padding)\n",
    "    \n",
    "    elif layer_type == 'fc':\n",
    "        \n",
    "        w = layer['w']\n",
    "        b = layer['b']\n",
    "        \n",
    "        shape = input_.get_shape().as_list()\n",
    "        dim = np.prod(shape[1:])            \n",
    "        flatten = tf.reshape(input_, [-1, dim])\n",
    "        \n",
    "        output = tf.matmul(flatten, w) + b\n",
    "        \n",
    "    elif layer_type == 'dropout':\n",
    "        \n",
    "        params = layer['params']\n",
    "        keep_prob = params['keep_prob']\n",
    "        \n",
    "        #output = tf.nn.dropout(input_, keep_prob)\n",
    "        output = tf.layers.dropout(input_, 1. - keep_prob, training=training)\n",
    "        \n",
    "    elif layer_type == 'relu':\n",
    "        \n",
    "        output = tf.nn.relu(input_)\n",
    "        \n",
    "    elif layer_type == 'sigmoid':\n",
    "        \n",
    "        output = tf.nn.sigmoid(input_)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def build_model(model, X, y, training):\n",
    "    \"\"\"\n",
    "    Build model operation\n",
    "    \n",
    "    Inputs:\n",
    "    - model: CNN model layer \n",
    "    - X: tf placeholder\n",
    "    - y: tf placeholder\n",
    "    \n",
    "    Returns a tuple of tensorflow graph op:\n",
    "    - loss_: model loss\n",
    "    - pred: model prediction\n",
    "    - acc: model accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ = X\n",
    "    for layer in model:\n",
    "        layer_type = layer['name']\n",
    "        sub_layers = layer_type.split('_')\n",
    "        \n",
    "        for sub_layer in sub_layers:\n",
    "            output = build_layer(input_, layer, sub_layer, training)\n",
    "            input_ = output\n",
    "            \n",
    "    # compute loss\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # regularization\n",
    "    for layer in model:\n",
    "        layer_type = layer['name']\n",
    "        sub_layers = layer_type.split('_')\n",
    "        \n",
    "        # TODO: refactor me\n",
    "        for sub_layer in sub_layers:\n",
    "            if sub_layer == 'conv':\n",
    "                params = layer['conv_params']\n",
    "                if 'l2_reg' in params:\n",
    "                    alpha = params['l2_reg']\n",
    "                    loss += (alpha * tf.nn.l2_loss(layer['w']))\n",
    "                \n",
    "            elif sub_layer == 'fc':\n",
    "                params = layer['params']\n",
    "                if 'l2_reg' in params:\n",
    "                    alpha = params['l2_reg']\n",
    "                    loss += (alpha * tf.nn.l2_loss(layer['w']))\n",
    "            \n",
    "    # prediction\n",
    "    pred = tf.argmax(tf.nn.softmax(output), axis=-1) \n",
    "    \n",
    "    # accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(y, axis=-1), pred)\n",
    "    correct_pred = tf.cast(correct_pred, tf.float32)\n",
    "    acc = tf.reduce_mean(correct_pred)\n",
    "    \n",
    "    return loss, pred, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimize(model, sess, config, X, y, training):\n",
    "    \"\"\"\n",
    "    Run model optimization\n",
    "    \n",
    "    Inputs:\n",
    "    - model: CNN model\n",
    "    - sess: tensroflow graph session\n",
    "    - config: optimization config\n",
    "    - X: image input tensorflow tensor\n",
    "    - y: label input tensorflow tensor\n",
    "    \n",
    "    Returns:\n",
    "    - model: optimized CNN model\n",
    "    - loss_history: loss history\n",
    "    \"\"\"\n",
    "    \n",
    "    # config\n",
    "    Xs, ys = config['train_data']\n",
    "    X_test_sc, y_test_en = config['test_data']\n",
    "    batch_size = config['batch_size']\n",
    "    epochs = config['epochs']\n",
    "    \n",
    "    train_op = config['train_op']\n",
    "    loss_op = config['loss_op']\n",
    "    pred_op = config['pred_op']\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "   \n",
    "        batch_loss = []\n",
    "        batch_acc = []\n",
    "        \n",
    "        for X_batch, y_batch in next_batch(Xs, ys, batch_size): \n",
    "            _, loss = sess.run([train_op, loss_op], \n",
    "                               feed_dict = { X: X_batch, y: y_batch, training: True})\n",
    "            acc = sess.run(acc_op, feed_dict={ X: X_batch, y: y_batch, training: False })\n",
    "            \n",
    "            batch_loss.append(loss)\n",
    "            batch_acc.append(acc)\n",
    "            \n",
    "        avg_loss = np.mean(batch_loss)\n",
    "        avg_acc = np.mean(batch_acc)\n",
    "        \n",
    "        loss_history.append(avg_loss)\n",
    "        \n",
    "        #test_acc = sess.run(acc_op, feed_dict = { X: X_test_sc, y: y_test_en, training: False })\n",
    "        if (e + 1) % 5 == 0:\n",
    "            print('[{:3d}|{:3d}] avg loss: {:.4f} avg acc: {:.4f}'.format(\n",
    "                e + 1, epochs, avg_loss, avg_acc * 100))    \n",
    "        \n",
    "        # ugly early stop \n",
    "        #if test_acc  > 0.96:\n",
    "        #    break\n",
    "        \n",
    "        \n",
    "    return model, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-191e743d97ed>:95: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# tf placeholder\n",
    "X_feed = tf.placeholder(tf.float32, (None, 64, 64, 3))\n",
    "y_feed = tf.placeholder(tf.float32, (None, 6))\n",
    "training = tf.placeholder(tf.bool)\n",
    "    \n",
    "# prepare operations \n",
    "loss_op, pred_op, acc_op = build_model(model, X_feed, y_feed, training)\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = adam.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type       | Output Size  | Kernel Size  | Stride | Padding | L2 reg\n",
      "------------------------------------------------------------------------------\n",
      "conv       | (64, 64, 8)  | (3, 3)       | 1      | SAME    | 1.0e-03\n",
      "relu       | (64, 64, 8)  |              |        |         |       \n",
      "pool       | (32, 32, 8)  | (2, 2)       | 2      | VALID   |       \n",
      "conv       | (32, 32, 16) | (3, 3)       | 1      | SAME    | 1.0e-03\n",
      "relu       | (32, 32, 16) |              |        |         |       \n",
      "pool       | (16, 16, 16) | (2, 2)       | 2      | VALID   |       \n",
      "conv       | (16, 16, 32) | (3, 3)       | 1      | SAME    | 1.0e-03\n",
      "relu       | (16, 16, 32) |              |        |         |       \n",
      "pool       | (8, 8, 32)   | (2, 2)       | 2      | VALID   |       \n",
      "conv       | (8, 8, 64)   | (3, 3)       | 1      | SAME    | 1.0e-03\n",
      "relu       | (8, 8, 64)   |              |        |         |       \n",
      "pool       | (4, 4, 64)   | (2, 2)       | 2      | VALID   |       \n",
      "dropout    | (4, 4, 64)   |              |        |         |       \n",
      "fc         | 128          |              |        |         | 1.0e-03\n",
      "relu       | 128          |              |        |         |       \n",
      "fc         | 6            |              |        |         | 1.0e-03\n"
     ]
    }
   ],
   "source": [
    "input_size = (64, 64, 3)\n",
    "model_summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5| 50] avg loss: 1.1968 avg acc: 72.9167\n",
      "[ 10| 50] avg loss: 0.7891 avg acc: 92.5000\n",
      "[ 15| 50] avg loss: 0.5817 avg acc: 96.0417\n",
      "[ 20| 50] avg loss: 0.5165 avg acc: 98.3333\n",
      "[ 25| 50] avg loss: 0.4090 avg acc: 99.0625\n",
      "[ 30| 50] avg loss: 0.3893 avg acc: 99.3750\n",
      "[ 35| 50] avg loss: 0.3396 avg acc: 99.6875\n",
      "[ 40| 50] avg loss: 0.3010 avg acc: 99.5833\n",
      "[ 45| 50] avg loss: 0.3045 avg acc: 99.7917\n",
      "[ 50| 50] avg loss: 0.2409 avg acc: 99.8958\n",
      "Train accuracy 99.9020\n",
      "Test accuracy 97.2222\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    config = { \n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'train_data': (X_train_sc, y_train_en),\n",
    "        'test_data': (X_test_sc, y_test_en),\n",
    "\n",
    "        # ops\n",
    "        'train_op': train_op,\n",
    "        'loss_op': loss_op,\n",
    "        'pred_op': pred_op,\n",
    "        'acc_op': acc_op\n",
    "    }\n",
    "    \n",
    "    model, loss_hist = model_optimize(model, sess, config, X_feed, y_feed, training)\n",
    "    \n",
    "    plt.title('Model loss throuhg epochs learning rate {:1.0e}'.format(learning_rate))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.plot(np.arange(1, len(loss_hist) + 1), loss_hist)\n",
    "    plt.xlim(xmin=1, xmax=len(loss_hist))\n",
    "\n",
    "    train_acc = sess.run(acc_op, feed_dict={ X_feed: X_train_sc ,y_feed: y_train_en, training: False })\n",
    "    print('Train accuracy {:4.4f}'.format(train_acc * 100))\n",
    "    \n",
    "    test_acc = sess.run(acc_op, feed_dict={ X_feed: X_test_sc, y_feed: y_test_en, training: False })\n",
    "    print('Test accuracy {:4.4f}'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
